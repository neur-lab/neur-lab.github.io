<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>News</title>
    <link rel="stylesheet" href="css/style.css">
    <link rel="stylesheet" href="css/news.css">
    <link href="https://fonts.googleapis.com/css2?family=Staatliches&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Archivo&display=swap" rel="stylesheet">
</head>

<body>
    <div id="header"></div>
    <main style="background-color: #fffbf0;">
        <div class="other-head">
            <h1 style="color: #f0fbff; font-family: 'Staatliches', sans-serif;">NEWS</h1>
        </div>

        <div class="news-main">
            <style>
                .news-main ul {
                    list-style: none;
                    padding-left: 0;
                }

                .news-main li {
                    margin-bottom: 20px;
                }
            </style>

            <h3>No news is good news.</h3>
            <p>Information regarding applications for graduate and undergraduate research positions will be updated
                soon.</p>

            <hr>

            <h4>Important Papers</h4>

            <p>Here are the papers I consider fundamental:</p>

            <ul>
                <li>
                    <b>1. Attention Is All You Need</b><br>
                    <i>(Most important)</i><br>
                    <a href="https://arxiv.org/abs/1706.03762" target="_blank">Paper Link</a>
                </li>
                <li>
                    <b>2. Pre-training of Deep Bidirectional Transformers for Language Understanding (BERT)</b><br>
                    <i>(Foundational for the NLP field)</i><br>
                    <a href="https://arxiv.org/abs/1810.04805" target="_blank">Paper Link</a>
                </li>
                <li>
                    <b>3. An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale (ViT)</b><br>
                    <i>(Pioneering work for the vision field)</i><br>
                    <a href="https://arxiv.org/abs/2010.11929" target="_blank">Paper Link</a>
                </li>
                <li>
                    <b>4. Learning Transferable Visual Models From Natural Language Supervision (CLIP)</b><br>
                    <i>(Connecting vision and language)</i><br>
                    <a href="https://arxiv.org/abs/2103.00020" target="_blank">Paper Link</a>
                </li>
                <li>
                    <b>5. Visual Instruction Tuning (LLaVA)</b><br>
                    <i>(Large Vision-Language Models)</i><br>
                    <a href="https://arxiv.org/abs/2304.08485" target="_blank">Paper Link</a>
                </li>
            </ul>

            <h5>Optional</h5>

            <ul>
                <li>
                    <b>6. Denoising Diffusion Probabilistic Models (DDPM)</b><br>
                    <i>(If you are interested in diffusion models â€” I am not an expert in this field, but I would like
                        to gain experience.)</i><br>
                    <a href="https://arxiv.org/abs/2006.11239" target="_blank">Paper Link</a>
                </li>
            </ul>
        </div>

        <section class="contact">
            <div class="contact-title">
                <h2 style="font-family: 'Staatliches', sans-serif;">Contact</h2>
            </div>
            <div id="contact"></div>
        </section>
    </main>

    <div id="footer"></div>
    <script src="js/main.js"></script>
</body>


</html>